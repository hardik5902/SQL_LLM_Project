{"doc_id": "21086d6a-aefc-49db-8af1-b76cf301a094", "source_type": "email", "title": "Re: Order Issue - ORD0023", "sender": "support@company.com", "body": "Dear Customer,\n\nThank you for reaching out about your recent order (ORD0023). We're sorry to hear that the product arrived damaged. We take quality issues very seriously.\n\nOur support team has initiated a replacement, and you should receive it within 5-7 business days. In the meantime, please dispose of the damaged product or return it using the prepaid label attached.\n\nIf you have any further concerns, feel free to reply to this email.\n\nSincerely,\nSupport Team\nCompany Inc.\n", "filename": "sample_email.eml", "created_at": "2025-05-21T17:20:31.531013"}
{"doc_id": "e7679cb0-a423-4975-88a8-a146f18ad824", "source_type": "pdf", "title": "Analytical Study and Recommendations for Computer Vision Methods", "body": " \nAnalytical Study and Recommendations for \nComputer Vision Methods \nDyuti Vartak \nDepartment of Computer Science \n& Engineering (Data Science) \nDwarkadas J. Sanghvi College of \nEngineering \nMumbai, India \nvartakdyuti@gmail.com \n \nYogesh Maheshwari \n Department of Computer Science  \n& Engineering (Data Science) \n Dwarkadas J. Sanghvi College \nof Engineering \nMumbai, India \nyogeshgm1234@gmail.com \n \nTanishka Kothari \nDepartment of Computer Science \n& Engineering (Data Science) \nDwarkadas J. Sanghvi College of \nEngineering \nMumbai, India \ntanishka.k.kothari@gmail.com \n \n \nDr. Kriti Srivastava \nDepartment of Computer Science \n& Engineering (Data Science) \nDwarkadas J. Sanghvi College of \nEngineering \nMumbai, India \nkriti.srivastava@djsce.ac.in\nAbstract - The purpose of this comparative study is to determine \nthe effectiveness of various computer vision techniques for image \nanalysis tasks. This research aims to investigate different \ncomputer vision models for object detection and recognition. \nUsing computer vision models for object detection and \nrecognition, this research aims to replace the cumbersome manual \nsystem currently in use. This is accomplished by comparing \npopular models such as YOLO and Haar Cascade based on their \nprecision, speed, and efficiency. In addition, facial recognition \nmethods, such as the Siamese Model and the face-recognition \nlibrary, are analyzed based on their performance using metrics \nsuch as time, and similarity scores. The challenges and limitations \nof each approach are examined to identify the most suitable model \nfor specific tasks. As a proof of concept, this study concludes by \nimplementing its recommendation on a popular use case. \nI. \nINTRODUCTION \nThe objective of this research is to comprehensively assess \ncomputer vision techniques employed in image analysis tasks. \nWith the continuous progress in computer vision, it has become \na promising technology for various applications such as \ndetecting objects, recognizing faces, and reconstructing scenes. \nTo aid decision-makers in choosing the most suitable computer \nvision method for their image analysis requirements, this report \nconducts an evaluation of the effectiveness of different \ncomputer vision techniques and offers recommendations based \non the findings. The comparative analysis in this report includes \npopular models like YOLO and Haar Cascade, considering \ntheir precision, speed, and effectiveness. Facial recognition \napproaches like the Siamese Model and face-recognition library \nare examined and compared using metrics such as time, \nsimilarity scores, and threshold. Additionally, the report \nconsiders the challenges and limitations associated with each \nmethod to identify the most appropriate model for specific \ntasks. The study results provide valuable insights into the \nefficiency of various computer vision techniques and their \npractical applications. The recommendations presented in this \nreport can guide decision-makers in selecting the most suitable \ncomputer vision methodology for their image analysis needs. \nFurthermore, this report contributes to the advancement of \ncomputer vision research by identifying the strengths and \nweaknesses of different methods and proposing solutions for \nfuture enhancements. \nThe need for the research work is to address the lack of clear \nguidance and information for decision-makers in selecting the \nmost appropriate computer vision methodology for their image \nanalysis needs. With the increasing advancements in computer \nvision technologies and the wide range of available \nmethodologies, it has become increasingly challenging to \nchoose the most suitable methodology for specific image \nanalysis tasks, leading to suboptimal performance or wasted \nresources. Furthermore, computer vision technologies have \nbecome increasingly important across diverse fields, making it \nessential to provide a comprehensive comparative analysis of \nvarious methodologies and their performance for image \nanalysis tasks. Therefore, the research aims to identify the most \neffective computer vision methodologies based on precision, \nswiftness, and effectiveness, enabling decision-makers to select \nthe most appropriate methodology for their image analysis \nrequirements and ensure optimal performance and resource \nutilization. In addition to guiding decision-makers, the research \nalso aims to contribute to the progress of computer vision \nresearch by providing valuable insights into the strengths and \nlimitations of different methodologies and their applications. \nBy identifying the most effective methodologies and their \napplications, the study can help guide future research in \ncomputer vision and enhance the development of new and \nimproved methodologies. \n \nThis research focuses primarily on object detection and facial \nrecognition. The paper is separated into various sections. The \nsecond section consists of a literature review discussing the \nlimitations and a comparative analysis of the object detection \nalgorithms YOLO and Haar Cascade.. Additionally, it also \npresents a literature review that provides an overview of various \nface recognition algorithms, their limitations, and a comparison \nof the top two algorithms, the Siamese Model, and the face-\nrecognition library. The third section provides an empirical \nstudy and comprehensive analysis of the results obtained from \nusing the two recommended algorithms for object detection and \nface recognition, based on various datasets. The fourth section \ndescribes a use-case attendance system developed based on the \nfindings of the previous sections. Finally, the fifth section \nconcludes the research work with recommendations. \nIEEE - 56998\n14th ICCCNT IEEE Conference \nJuly 6-8, 2023 \nIIT - Delhi, Delhi, India \n2023 14th International Conference on Computing Communication and Networking Technologies (ICCCNT) | 979-8-3503-3509-5/23/$31.00 \u00a92023 IEEE | DOI: 10.1109/ICCCNT56998.2023.10308209\nAuthorized licensed use limited to: University of Washington Libraries. Downloaded on April 10,2025 at 01:02:59 UTC from IEEE Xplore.  Restrictions apply. \nII. \nLITERATURE REVIEW \nTo ensure that the most effective methods were selected for the \ncomparative study, an extensive literature review was \nconducted. This review involved a thorough investigation of \npublished works to identify the most accurate and reliable \nmethods for the given research objectives. The aim of this \nprocess was to gather information and knowledge about various \ntechniques and approaches which could help in determining the \noptimal methods for the study. \n \n2.1 Object Detection \nObject detection is a computer vision technique involving the \nidentification and localisation of objects in images or videos. \nThis method is indispensable in numerous disciplines, \nincluding robotics, autonomous vehicles, and security \nsurveillance. Typically, deep learning models such as CNNs are \nutilised by object detection methods to identify and classify \nobjects within an image. Notable object detection algorithms \ninclude YOLO (You Only Look Once), Faster R-CNN (Region \nConvolutional Neural Network), and SSD (Single Shot \nMultiBox Detector). From detecting pedestrians in traffic to \nrecognising objects in satellite imagery, these algorithms have \nfound widespread use in a variety of contexts. \n \nAuthors Guennouni, Ahaitouf, and Mansouri compare the \neffectiveness of Haar-like feature selection and Local Binary \nPatterns (LBP) for multiple object detection across various \nplatforms utilizing the OpenCV library and Viola-Jones \nalgorithm for Haar-like features and the LBPH algorithm for \nLBP features [1]. The study examines the evolution of object \ndetection techniques and highlights the significance of feature \nselection. However, the study contains a number of research \ngaps. Inadequate and incomplete review of the state-of-the-art \nin object detection techniques, limited investigation of other \nfeature selection methods or algorithms, and a limited number \nof tested platforms are a few of these limitations. In addition, \nthe study lacks a comprehensive analysis of the results and their \npractical applications. Consequently, additional research is \nnecessary to address these gaps and advance object detection \ntechniques. \n \nAuthors Alexey Bochkovskiy, Chien-Yao Wang, and Hong-\nYuan Mark Liao present a cutting-edge object detection \nalgorithm that combines multiple innovative techniques to \nachieve exceptional accuracy and speed [2]. The study conducts \na thorough review of existing research in object detection and \ncompares the newly proposed YOLOv4 algorithm with prior \napproaches, demonstrating its superior performance in both \naccuracy and speed. The authors introduce several significant \ninnovations, such as a novel backbone network, a new data \naugmentation technique, and a fresh loss function. However, \nthe study falls short in fully analysing the impact of each \ninnovation on overall performance, examining the trade-off \nbetween accuracy and speed, or evaluating the performance of \nYOLOv4 in detecting small objects. Further research is needed \nto address these limitations and advance the state-of-the-art in \nobject detection algorithms. \n \nAuthors Sahal, Kurniawan, and Kadir introduce a new method \nfor object detection in autonomous vehicles using a single \ncamera and the YOLOv4 algorithm [3]. The authors claim that \nthis technique can significantly reduce the cost and complexity \nof object detection systems for autonomous vehicles. They \nprovide a detailed explanation of their proposed approach and \npresent experimental results that demonstrate its effectiveness. \nTheir method achieved higher accuracy than standard \ntechniques while maintaining real-time performance. The \nauthors briefly review the existing literature on object detection \nfor autonomous vehicles and argue that their approach \nrepresents a significant simplification of the object detection \nprocess. While the paper highlights the potential of their \nmethod to reduce costs and simplify installation, further \nresearch is required to validate the approach in a broader range \nof driving scenarios and address potential limitations. \n \nAuthors Wang Hao, and Nangfeng Xiao present an enhanced \nversion of the YOLOv4 algorithm tailored for detecting objects \nunderwater, which is a challenging task due to factors such as \nlow visibility and distortions caused by water [4]. To address \nthese challenges, the authors introduce modifications to the \nbackbone network, additional convolutional layers, and a new \nfeature fusion strategy. Using standard metrics such as mean \naverage precision and intersection over union, the accuracy of \nthe proposed algorithm is demonstrated to be superior to that of \nthe original YOLOv4 algorithm. According to the conclusion \nof the paper, the proposed algorithm has the potential to be \nutilised in a wide range of underwater applications. The authors \nemphasise, however, that additional research is required to \nimprove the algorithm's performance in challenging underwater \nenvironments. \n \nAuthors Paul Viola, and Michael Jones introduce a new \nalgorithm for object detection that combines fast processing \ntime with high accuracy [5]. The algorithm uses a series of \nweak classifiers, trained with an adapted version of the \nAdaBoost algorithm and simple features such as Haar wavelets, \nto detect objects at multiple scales. The paper presents \nexperimental results on the face detection task, demonstrating \nthat the proposed algorithm achieves top-level performance on \na standard dataset while running in real-time. Due to its \nsignificant contribution to the field of computer vision, the \npaper has received widespread attention and has influenced \nsubsequent research on object detection algorithms. \n \nAuthors Christian Herdianto Setjo, Balza Achmad, and Faridah \nintroduce a novel technique for human detection in thermal \nimages through the use of a Haar-cascade classifier [6]. The \nauthors provide a comprehensive explanation of the \nmethodology, \nwhich \nincludes \npre-processing, \nfeature \nextraction, classifier training, and testing. The evaluation of the \nproposed approach is presented in detail, showcasing \nsensitivity, specificity, and accuracy measures. The results \nindicate that the approach is efficient in detecting humans in \ndifferent positions and poses with low computational \nIEEE - 56998\n14th ICCCNT IEEE Conference \nJuly 6-8, 2023 \nIIT - Delhi, Delhi, India \nAuthorized licensed use limited to: University of Washington Libraries. Downloaded on April 10,2025 at 01:02:59 UTC from IEEE Xplore.  Restrictions apply. \nrequirements. Additionally, the authors recommend future \nresearch directions, such as exploring the use of deep learning \ntechniques. \n \nAuthors Mimboro, Heryadi, Lukas, Suparta, and Wibowo \npresent a novel approach to addressing traffic congestion in \nurban areas through a real-time vehicle counting method using \na Haar Cascade Classifier model [7]. The authors explain the \nconcept of the Haar Cascade Classifier and provide a detailed \ndescription of their proposed method, which involves \nprocessing a video stream captured by a camera. The article \nalso includes a number of experiments to evaluate the precision \nand performance of the proposed method; the results \ndemonstrate a high level of precision and real-time \nperformance.  The authors discuss the practical applications of \ntheir proposed method in traffic management and surveillance \nsystems, emphasising its capacity to enhance traffic flow and \nsafety. The article concludes with a significant contribution to \nthe fields of computer vision and machine learning for the \npurposes of traffic management and surveillance. \n \nAuthors Adri Priadana, and Muhammad Habibi present a novel \napproach to detect and filter out selfies from Instagram using \nthe Haar cascades algorithm for face detection [8]. A dataset of \n10,000 images was collected and processed to obtain a final set \nof 2,500 face images. Using a machine learning algorithm, the \nauthors were able to classify images as either selfies or non-\nselfies with an accuracy rate of 82%. The study suggests that \nreducing the number of selfies on social media platforms can \nhave a positive impact on mental health. Overall, the proposed \nmethod can contribute to improving the quality of online \ncontent by filtering out low-quality selfies. \n \nThus, when compared to other object detection methods, \nYOLO stands out for its rapid processing speed and \ncomputation, particularly in real-time scenarios. Moreover, \nYOLO delivers high accuracy while minimizing the \noccurrence of background errors, which are often found in \nother methods. This is because the YOLO architecture allows \nthe model to efficiently learn and recognize a diverse range of \nobjects. Overall, YOLO is considered one of the most effective \nmethods for object detection in real-time situations, surpassing \nother methods in terms of accuracy and speed, depending on \nthe hardware used. Apart from object detection, YOLO can \nalso be used for identifying individuals, animals, and vehicles. \nThe Haar Cascade method offers several advantages over other \nobject detection methods. It delivers high accuracy when \ncorrectly trained and tested and is computationally efficient, \nenabling real-time object detection. The method is adaptable, \ncapable of detecting objects of various shapes, sizes, and \norientations \nwith \ncustomizable \ndetection \nparameters. \nMoreover, Haar Cascade is straightforward to implement and \ncan be integrated into various software platforms and \nprogramming languages. Finally, the method is resilient to \nchanges in lighting, background, and image noise, making it \nsuitable for a range of computer vision applications. Thus, \nYOLO and Haar Cascade have been selected as the methods \nfor comparative analysis. \n \nObject detection techniques offer a versatile solution for a range \nof tasks such as counting, detecting, and tracking. However, \ntheir ability to simply detect the presence of an object may not \nbe sufficient in certain situations. For instance, consider an \nattendance system that requires individual student recognition \nto mark their attendance accurately. Although methods like \nYOLO and Haar Cascade are designed to identify objects in \nimages and videos, they may not be equipped to recognize \nindividual faces. To achieve the desired outcome, a face \nrecognition model is necessary. This machine learning model \nhas the capability to identify and recognize human faces, \nenabling the attendance system to mark each student's \nattendance based on their unique facial features. Therefore, \nwhile object detection methods are valuable for several \npurposes, including identifying objects and people, additional \nfeatures such as face recognition are essential for some \napplications like attendance marking to attain accurate results. \n \n2.2 Face Recognition \nFacial recognition techniques have gained significant \npopularity in recent times owing to their extensive utilization in \nsecurity, marketing, and personalization. These methods \nemploy artificial intelligence and machine learning algorithms \nto examine and contrast facial attributes, including eye distance \nand nose shape, with the goal of identifying specific \nindividuals. This procedure has demonstrated remarkable \nprecision and has found applications in diverse scenarios, \nranging from smartphone unlocking to the tracking of criminal \nsuspects. \n \nAuthors Koch, Zemel, and Salakhutdinov present an innovative \nstrategy for one-shot image recognition utilizing a Siamese \nneural network architecture [21]. This method can identify new \nobjects with just one or a limited number of examples. The \nSiamese network is composed of two equivalent convolutional \nneural networks that have the same weights and receive input \nfrom image pairs. The authors assess the effectiveness of their \napproach on the Omniglot dataset and demonstrate exceptional \nperformance, surpassing other techniques. The proposed \nSiamese neural network is a suitable solution for one-shot \nimage recognition problems, with potential applications in \ndisciplines including computer vision, robotics, and natural \nlanguage processing. \n \nAuthors Taigman, Yang, Ranzato, and Wolf outline a novel \ndeep learning approach named DeepFace that attained a level \nof performance equivalent to that of humans in face verification \ntasks [22]. The authors employed a convolutional neural \nnetwork structure and trained it on an extensive collection of \nfacial images. The model exhibited substantially higher \naccuracy than previous state-of-the-art systems on benchmark \ndatasets and introduced a new loss function known as triplet \nloss. The significance of the DeepFace model lies in its capacity \nto learn facial features and recognize individuals across various \nIEEE - 56998\n14th ICCCNT IEEE Conference \nJuly 6-8, 2023 \nIIT - Delhi, Delhi, India \nAuthorized licensed use limited to: University of Washington Libraries. Downloaded on April 10,2025 at 01:02:59 UTC from IEEE Xplore.  Restrictions apply. \nposes, expressions, and lighting conditions. It has potential \napplications in security and law enforcement, as well as social \nmedia and e-commerce. \n \nAuthors Florian Schroff, Dmitry Kalenichenko, and James \nPhilbin describe a deep learning approach for face recognition \nand clustering by creating a high-dimensional embedding space \n[23]. The authors introduce an innovative loss function that \ntrains the model with triplets of images to optimize the \ndistances between faces in the embedding space. They \ndemonstrate exceptional performance on face recognition \nbenchmarks and superior results on face clustering. The paper \nemphasizes the significance of data augmentation and hard \nnegative mining in training the model and discusses the \nchallenges of learning effective face representations. The \nFaceNet model has gained wide acceptance in subsequent \nstudies in the field. \n \nAuthors Yi Sun, Xiaogang Wang, and Xiaoou Tang present a \nnovel method for face recognition utilizing very deep neural \nnetworks [24]. The proposed DeepID3 model comprises a deep \nCNN, a max-pooling layer, and an MLP, integrating several \ninnovative design choices, including fractional max-pooling \nand multi-task learning. The model exhibits state-of-the-art \nperformance on various benchmark face recognition datasets, \nindicating its potential as a propitious direction for future \nresearch. \n \nAuthors Amira Anisa Rahman Putra, and Samsul Setumin \nexamine the utilization of Siamese neural networks in face \nrecognition and the influence of different activation functions \non their performance [25]. The authors provide an overview of \nface recognition techniques and discuss the significance of \nactivation functions in neural networks. They present a \ncomprehensive analysis of commonly used activation functions \nand assess their performance in face recognition experiments \non the LFW dataset. The findings indicate that ReLU and ELU \nactivation functions outperform sigmoid and tanh, while leaky \nReLU exhibits similar performance to ReLU. In conclusion, the \npaper demonstrates the efficacy of Siamese neural networks in \nface recognition and the criticality of selecting appropriate \nactivation functions to attain optimal performance. \n \nAuthor Ashwin Rao introduces a real-time attendance system \nthat relies on face recognition [26]. The paper deliberates on the \nbenefits and drawbacks of utilizing face recognition for \nattendance tracking and presents the architecture of the \nproposed system that comprises a face detection, a feature \nextraction, and a classification module. The experiments \ndemonstrate that the system achieves an accuracy rate of 95.5% \non a dataset of 200 faces, indicating its potential to substitute \ntraditional methods of attendance tracking. \n \nAuthors Shizhen Huang, and Haonan Luo introduce a novel \nattendance system that employs dynamic face recognition, \nutilizing deep learning algorithms and real-time video analysis \nto record attendance with precision and efficiency [27]. The \nauthors conduct a literature review on face recognition systems \nand emphasize the drawbacks of conventional attendance \nsystems. Additionally, the technical aspects of the suggested \nsystem are explored, and experimental results confirming its \neffectiveness are presented. The article concludes by \nunderlining the potential benefits of the proposed system and \nsuggesting promising areas for future research. In summary, the \npaper provides an extensive survey of the literature on face \nrecognition technology and offers a feasible application for the \nproposed attendance system. \n \nAuthors Harikrishnan, Sudarsan, Sadashiv, and Ajai provide a \ncomprehensive review of the literature on the use of face \nrecognition technology in surveillance systems, with specific \nattention to attendance monitoring [28]. The authors critique \nthe shortcomings of conventional attendance monitoring \nsystems and advocate for a more advanced approach that \nleverages deep learning and computer vision techniques. The \npaper presents a solution in the form of the V-FRAMS , which \ninvolves the deployment of a pre-trained convolutional neural \nnetwork (CNN) model to detect and recognize faces, and an \nautomated attendance tracking system to register attendance \ndata. The authors assert that the V-FRAMS system has the \npotential to revolutionize attendance monitoring across \ndifferent settings. \n \nConsequently, research reveals the Siamese Model to be a \nhighly effective model for recognizing faces, owing to its \nspecialized design for learning similarity metrics between two \ninput images. This feature makes it particularly well-suited for \nface recognition, allowing it to identify faces that may appear \nin different lighting conditions or from varying angles. Studies \nhave shown that Siamese networks demonstrate superior \naccuracy in face recognition tasks compared to other popular \nmodels such as VGGFace and FaceNet. Additionally, this \nmodel requires fewer training examples than other deep \nlearning models and can be readily adapted to recognize new \nfaces. Overall, the Siamese model's ability to learn a robust \nsimilarity metric, achieve high accuracy, require fewer training \nexamples, and adapt to new faces makes it an outstanding \noption for face recognition tasks. It is important to avoid \nplagiarism by expressing the ideas in your own words and citing \nsources appropriately. The face-recognition library, on the \nother hand, stands out for its superior accuracy, speed, \nversatility, ease of use, and open-source nature. It leverages \ndeep learning algorithms and pre-trained models to detect and \nrecognize faces in images and videos with remarkable \nprecision, making it a suitable solution for a wide range of \napplications. Furthermore, it is compatible with various \ncameras and image formats and is relatively straightforward to \nuse, even for developers with limited experience in computer \nvision or deep learning. Its open-source nature means that it is \nfreely available and can be modified and enhanced by the \ndeveloper community, which has contributed to its broad \nacceptance in different industries and applications. It is \nessential to avoid plagiarism by rephrasing the ideas in one's \nown words and citing sources properly. Hence, the Siamese \nIEEE - 56998\n14th ICCCNT IEEE Conference \nJuly 6-8, 2023 \nIIT - Delhi, Delhi, India \nAuthorized licensed use limited to: University of Washington Libraries. Downloaded on April 10,2025 at 01:02:59 UTC from IEEE Xplore.  Restrictions apply. \nModel and the built-in Python library face-recognition have \nbeen selected as the models for the study. \n \nIII. \nEMPIRICAL STUDY AND ANALYSIS \nA research study was conducted to investigate the performance \nof object detection and face recognition methods using two \ndifferent datasets - a pre-built dataset and a custom dataset, for \nwhich the study was carried out in a classroom setting. \nEmpirical evidence was gathered and analyzed to determine the \neffectiveness of these methods in detecting and recognizing \nobjects and faces in the datasets. \n \n3.1 Data Collection and Pre-processing \nInitially, a dataset was generated by capturing images of \nstudents' faces via a webcam. Later, images of students seated \nin a classroom were used to create the testing data. For training \nthe Siamese model, a pre-existing dataset was utilized for \nnegative images. \n \n3.2 Result Analysis of Object Detection Methods \nBased on the dataset mentioned earlier, an analysis was \nconducted using both the Haar Cascade and YOLO object \ndetection methods. The results were compared and it was \ndetermined that the Haar Cascade method outperformed the \nYOLO method. \n \n3.2.1 Performance Evaluation of Haar Cascade \nTo implement Haar cascade, a folder was created to store all the \nimages. After running the algorithm, all the faces detected were \nstored in a 100x100 size. The input for Haar cascade was an \nimage, which was then used to detect all the face locations, crop \nthem, and store them. Remarkably, as seen in fig 3.2.1, Haar \ncascade was able to accurately detect the students, even those \nwho were seated in the back of the classroom, thus achieving a \nhigh accuracy for each image. It identified 33 out of the 38 \nstudents present in the classroom, resulting in an accuracy of \n86.84%. \n \n \nFig 3.2.1: Detection using Haar Cascade \n \n3.2.2 Performance Evaluation of YOLO \nIn order to employ YOLO, a compilation of images was \ncombined and compressed to produce a video. YOLO was then \nutilized to analyse the video and generate a new output video \ncontaining object detection. Besides identifying individuals, the \nalgorithm was also capable of detecting other objects. YOLO \nwas able to recognize 27 out of a total of 38 students, resulting \nin a lower accuracy of 71.05%. Furthermore, it also identified \nother objects such as benches, books, backpacks, chairs, and so \non, as shown in Figure 3.2.2. \n \n \nFig 3.2.2: Detection using YOLO \n \n3.3 Result Analysis of Face Recognition Methods \nAdditionally, a research study was conducted to compare two \ndifferent models of face recognition: the Siamese Model and \nthe face-recognition library. The study assessed the results \nbased on their similarity score, and both methods showed a high \nlevel of accuracy. However, the face-recognition library had a \nsuperior accuracy rate and was ultimately considered the better \nmethod due to its faster evaluation time. \n \n3.3.1 Performance Evaluation of Siamese Model \nTo train the Siamese model, three folders were created: \n\"anchor,\" \"positive,\" and \"negative.\" The \"anchor\" and \n\"positive\" folders contained images of faces that were to be \nrecognized, while the \"negative\" folder contained images of \ncelebrities. The Siamese model was then developed as a neural \nnetwork and trained using the images. It identifies the similarity \nscore between two images, and establishes a threshold which \ndeclares the two images as the same if the score exceeds that \nthreshold. Thus, as seen in fig 3.3.1, the model returns a very \nlow similarity score because the two images do not match. \n \nFig 3.3.1: Recognition using Siamese Model \n \n \n \n3.3.2 Performance Evaluation of face-recognition library \nIEEE - 56998\n14th ICCCNT IEEE Conference \nJuly 6-8, 2023 \nIIT - Delhi, Delhi, India \nAuthorized licensed use limited to: University of Washington Libraries. Downloaded on April 10,2025 at 01:02:59 UTC from IEEE Xplore.  Restrictions apply. \nThe face-recognition library was implemented by creating two \nfolders: \"known\" and \"unknown.\" The \"known\" folder \ncontained images of students, while the \"unknown\" folder \ncontained images of faces to be recognized. The tolerance \nthreshold was set to 0.5, which determined the strictness of the \nmodel in recognizing faces. When an image was placed in the \n\"unknown\" folder, the model checked it against every image in \nthe \"known\" folder and returned a match when it found one as \nseen in fig 3.3.2. \n \n \nFig 3.3.2: Recognition using face-recognition library \n \n3.4 Comparative Analysis \nAfter conducting research and comparing the results, it has been \ndetermined that Haar Cascade is a more effective method for \ndetecting objects than YOLO. Additionally, the face-\nrecognition library has been found to be a superior method for \nface recognition in comparison to the Siamese Model. This was \ndue to their higher level of accuracy and faster evaluation time. \nThese conclusions are supported by the data presented in fig \n3.4. \n \nFig 3.4: Comparative graphs of Accuracy and Time \nIV. \nPROOF OF CONCEPT \nBased on the comparison study conducted, it was concluded \nthat Haar Cascade and Face Recognition library are the most \neffective tools for object detection and face recognition, \nrespectively. As a proof of concept, this study proposes a design \nfor an attendance recording system that utilizes these methods \nto estimate and record the attendance of each student. This \nsystem serves as a use case for the practical application of Haar \nCascade and Face Recognition library in attendance \nmanagement as seen in fig 4.1. \n \n \nFig 4.1: Architectural diagram \n \nThe algorithm underwent training with several images \ncontaining the entire batch of students and their respective \nnames. The next step involved inputting the classroom images \ninto the system, which then utilized the Haar Cascade technique \nto identify the location of each face in the picture. \nSubsequently, the algorithm cropped the faces of all the \nstudents in the classroom and further processed them through \nthe face-recognition library model. Here, each cropped face was \ncompared to the set of trained faces of the students. When a \nmatch was detected, the algorithm recognized the student and \nmarked their attendance by displaying their name as shown in \nfig 4.2. \n \n \nFig 4.2: Model generated attendance \n \nV. \nCONCLUSION AND RECOMMENDATION \nAccording to the analysis and comparison made in the research \npaper, an individual application has been suggested for each of \nthe four methods that were studied: \n\u2022 The Haar Cascade method is useful for detecting and \ncropping faces in complex images. It works well when \nsubjects are located at varying depths within the image. \n\u2022 Yolo is a computer vision algorithm for real-time object \ndetection. It can efficiently detect multiple objects in \nvarious fields, including video surveillance, sports analysis, \nand medical imaging. \n\u2022 The Siamese neural network has applications in fields of \nimage similarity, image matching, and one-shot learning. It \ncan offer a customized solution that caters to specific \nindividual requirements. \nIEEE - 56998\n14th ICCCNT IEEE Conference \nJuly 6-8, 2023 \nIIT - Delhi, Delhi, India \nAuthorized licensed use limited to: University of Washington Libraries. Downloaded on April 10,2025 at 01:02:59 UTC from IEEE Xplore.  Restrictions apply. \n\u2022 The face-recognition library is a versatile tool that can learn \nfacial features. The library has applications in social media \nfor identifying tagged individuals and detecting emotions. \n \nAdditionally, recommendation by which each approach can be \nimproved in order to enhance its effectiveness: \n\u2022 To improve the performance of Haar Cascade, multiple \nstages of cascaded classifiers can be used to analyze images \nat various levels of depth and additional layers of classifiers \ncan be incorporated to improve accuracy. \n\u2022 To improve Yolo's performance, it can be trained with \nlarger and more diverse datasets to ensure that Yolo can \neffectively detect various objects across different scenarios \nand lighting conditions. \n\u2022 To enhance the performance of the Siamese model in use \ncases such as image retrieval, signature verification, and \ndocument plagiarism detection, several methods can be \nemployed, \nincluding, \nincreasing \nthe \ndataset \nsize, \naugmenting the dataset, fine-tuning the model, and \nincorporating attention mechanisms into the model \narchitecture. \n\u2022 To improve the face-recognition library for real-time \nprocessing use cases, it is suggested to incorporate more \nadvanced algorithms which can enhance the accuracy of \nfacial feature recognition and emotion detection. \n \nREFERENCES \n \n[1] Souhail Guennouni, Ali Ahaitouf, and Anass Mansouri \u2013 \u201cA Comparative \nStudy of Multiple Object Detection Using Haar-Like Feature Selection and \nLocal Binary Patterns in Several Platforms\u201d \u2013 2015. \n \n[2] Alexey Bochkovskiy, Chien-Yao Wang, and Hong-Yuan Mark Liao \u2013 \n\u201cYOLOv4: Optimal Speed and Accuracy of Object Detection\u201d \u2013 2020. \n \n[3] Mochammad Sahal, Ade Oktavianus Kurniawan, and Rusdhianto Effendi \nAbdul Kadir \u2013 \u201cObject Detection for Autonomous Vehicle using Single Camera \nwith YOLOv4 and Mapping Algorithm\u201d \u2013 2021. \n  \n[4] Wang Hao, and Nangfeng Xiao \u2013 \u201cResearch on Underwater Object \nDetection Based on Improved YOLOv4\u201d \u2013 2021. \n \n[5] Paul Viola, and Michael Jones \u2013 \u201cRapid Object Detection using a Boosted \nCascade of Simple Features\u201d \u2013 2002. \n \n[6] Christian Herdianto Setjo, Balza Achmad, and Faridah \u2013 \u201cThermal image \nhuman detection using Haar-cascade classifier\u201d \u2013 2020. \n \n[7] Prasetyo Mimboro, Yaya Heryadi, Lukas, Wayan Suparta, and Antoni \nWibowo \u2013 \u201cRealtime Vehicle Counting Method Using Haar Cascade Classifier \nModel\u201d \u2013 2021. \n \n[8] Adri Priadana, and Muhammad Habibi \u2013 \u201cFace Detection using Haar \nCascades to Filter Selfie Face Image on Instagram\u201d \u2013 2019. \n \n[9] Sai Likhitha Avupati, Abbineni Harshitha, Sai Pranavi Jeedigunta, Dirisala \nSai Chikitha Chowdary, and B. Pushpa \u2013 \u201cTraffic Rules Violation Detection \nusing YOLO and HAAR Cascade\u201d \u2013 2023 \n \n[10] William Tarimo, Moustafa M. Sabra, and Shonan Hendre \u2013 \u201cReal-Time \nDeep Learning-Based Object Detection Framework\u201d \u2013 2020. \n \n[11] R. Padilla, C. F. F. Costa Filho and M. G. F. Costa \u2013 \u201cEvaluation of Haar \nCascade Classifiers Designed for Face Detection\u201d \u2013 2012. \n \n[12] Truong Quang Vinh, and Nguyen Tran Ngoc Anh \u2013 \u201cReal-Time Face \nMask Detection Method Based on YOLOv3 Algorithm and Haar Cascade \nClassifier\u201d \u2013 2020. \n \n[13] Upulie H.D.I, and Lakshini Kuganandamurthy \u2013 \u201cReal-Time Object \nDetection using YOLO: A review\u201d \u2013 2021. \n \n[14] Andhy Panca Saputra, and Kusrini \u2013 \u201cWaste Object Detection and \nClassification using Deep Learning Algorithm: YOLOv4 and YOLOv4-tiny\u201d \u2013 \n2021. \n \n[15] Gaurav Ghosh, and K. S. Swarnalatha \u2013 \u201cA Detail Analysis and \nImplementation of Haar Cascade Classifier\u201d - 2022. \n \n[16] Rosa Andrie Asmara, Muhammad Ridwan, and Gunawan Budiprasetyo \u2013 \n\u201cHaar Cascade and Convolutional Neural Network Face Detection in Client-\nSide for Cloud Computing Face Recognition\u201d \u2013 2021. \n \n[17] Mahada Panji Anggadhita, and Yuni Widiastiwi \u2013 \u201cBreaches Detection in \nZebra Cross Traffic Light Using Haar Cascade Classifier\u201d \u2013 2020. \n \n[18] Rezha Aditya Maulana Budiman, Balza Achmad, Faridah, Agus Arif, \nNopriadi, and Luthfi Zharif \u2013 \u201cLocalization of white blood cell images using \nHaar Cascade classifiers\u201d \u2013 2016. \n \n[19] Orhan Arma\u011fan, and Mesud Kahriman \u2013 \u201cComparison of traditional haar \nclassifiers used in face detection applications with an alternative classifier for \nfour stages filtering\u201d \u2013 2014. \n \n[20] Jie Zhu, and Zhiqian Chen \u2013 \u201cReal Time Face Detection System Using \nAdaboost and Haar-like Features\u201d \u2013 2015. \n \n[21] Gregory Koch, Richard Zemel, and Ruslan Salakhutdinov \u2013 \u201cSiamese \nNeural Networks for One-shot Image Recognition\u201d \u2013 2015. \n \n[22] Yaniv Taigman, Ming Yang, Marc\u2019Aurelio Ranzato, and Lior Wolf \u2013 \n\u201cDeepFace: Closing the Gap to Human-Level Performance in Face \nVerification\u201d \u2013 2014. \n \n[23] Florian Schroff, Dmitry Kalenichenko, and James Philbin \u2013 \u201cFaceNet: A \nUnified Embedding for Face Recognition and Clustering\u201d \u2013 2014. \n \n[24] Yi Sun, Xiaogang Wang, and Xiaoou Tang \u2013 \u201cDeepID3: Face Recognition \nwith Very Deep Neural Networks\u201d \u2013 2015.  \n[25] Amira Anisa Rahman Putra, and Samsul Setumin \u2013 \u201cThe Performance of \nSiamese Neural Network for Face Recognition using Different Activation \nFunctions\u201d \u2013 2021. \n \n[26] Ashwin Rao \u2013 \u201cAttenFace: A Real Time Attendance System Using Face \nRecognition\u201d \u2013 2022. \n \n[27] Shizhen Huang, and Haonan Luo \u2013 \u201cAttendance System Based on \nDynamic Face Recognition\u201d \u2013 2020. \n \n[28] J. Harikrishnan, Arya Sudarsan, Aravind Sadashiv, and Remya A.S. Ajai \n\u2013 \u201cVision-Face Recognition Attendance Monitoring System for Surveillance \nusing Deep Learning Technology and Computer Vision\u201d \u2013 2019. \n \n[29] Ashish Yadav, Aman Sharma, and Sudeept Singh Yadav \u2013 \u201cAttendance \nManagement System Based on Face Recognition Using Haar-Cascade\u201d \u2013 2022. \n \n[30] Laiyun Qing, Shiguang Shan, and Wen Gao \u2013 \u201cEigen-harmonics faces: \nface recognition under generic lighting\u201d \u2013 2004. \n \n[31] Wenchao Zhang, Shiguang Shan, Wen Gao, Yizheng Chang, Bo Cao, and \nPeng Yang \u2013 \u201cInformation fusion in face identification\u201d \u2013 2016. \n \n[32] Golara Ghorban Dordinejad, and Hakan \u00c7evikalp \u2013 \u201cFace Frontalization \nfor Image Set Based Face Recognition\u201d \u2013 2022. \n \nIEEE - 56998\n14th ICCCNT IEEE Conference \nJuly 6-8, 2023 \nIIT - Delhi, Delhi, India \nAuthorized licensed use limited to: University of Washington Libraries. Downloaded on April 10,2025 at 01:02:59 UTC from IEEE Xplore.  Restrictions apply. \n[33] Zimeng Luo, Jiani Hu, Weihong Deng, and Haifeng Shen \u2013 \u201cDeep \nUnsupervised Domain Adaptation for Face Recognition \" \u2013 2018. \n \n[34] Laiyun Qing; Shiguang Shan; Xilin Chen \u2013 \u201cFace relighting for face \nrecognition under generic illumination\u201d \u2013 2004. \n \n[35] Shizhen Huang, and Haonan Luo \u2013 \u201cAttendance System Based on \nDynamic Face Recognition\u201d \u2013 2020. \n \n[36] Omar Abdul Rhman Salim, Rashidah Funke Olanrewaju, and Wasiu \nAdebayo Balogun \u2013 \u201cClass Attendance Management System Using Face \nRecognition\u201d \u2013 2018. \n \n[37] Saurabh Singh Rajawat, and Komal Saxena \u2013 \u201cFace Recognition based \nAttendance System\u201d \u2013 2022. \n \n[38] Shreyak Sawhney, Karan Kacker, Samyak Jain, Shailendra Narayan Singh, \nand Rakesh Garg \u2013 \u201cReal-Time Smart Attendance System using Face \nRecognition Techniques\u201d \u2013 2019. \n \n[39] Aruna Bhat, Shivam Rustagi, Shivi R Purwaha, and Shubhang Singhal \u2013 \n\u201cDeep-learning based group-photo Attendance System using One Shot \nLearning\u201d \u2013 2020. \n \n[40] Nazare Kanchan Jayant, Surekha Borra \u2013 \u201cAttendance management \nsystem using hybrid face recognition techniques\u201d \u2013 2016. \nIEEE - 56998\n14th ICCCNT IEEE Conference \nJuly 6-8, 2023 \nIIT - Delhi, Delhi, India \nAuthorized licensed use limited to: University of Washington Libraries. Downloaded on April 10,2025 at 01:02:59 UTC from IEEE Xplore.  Restrictions apply. \n", "filename": "Analytical_Study_and_Recommendations_for_Computer_Vision_Methods.pdf", "created_at": "2025-05-21T17:26:12.227278"}
{"doc_id": "40117079-5f06-426e-9b1e-a654cf013a91", "source_type": "pdf", "title": "", "body": "Company Inc.\n1234 Enterprise Way, Tech City, CA 90001\nsupport@company.com\nInvoice\nInvoice To:\nCustomer One\ncustomer1@example.com\nOrder ID: ORD0023\nInvoice Date: 2024-05-03\nItem\nQuantity\nUnit Price\nTotal\nEco Speaker\n1\n$129.99\n$129.99\nSubtotal\n$129.99\nTax (10%)\n$13.00\nTotal\n$142.99\nThank you for your purchase!\n", "filename": "invoice_ORD0023.pdf", "created_at": "2025-05-21T17:20:22.524714"}
{"doc_id": "e1d62428-0145-4a05-87d2-162a6d0d26dd", "source_type": "pdf", "title": "", "body": "Predictive Analysis of Freezing of Gait\nEvents in Parkinson\u2019s Disease Using\nAccelerometer Data and LGBM\nModeling: A Precision-Centric Approach\nRishi Doshi, Hardik Gupta, Praniket Walavalkar, Dyuti Vartak,\nand Narendra Shekokar\nAbstract The human body is prone to numerous neurological abnormalities that\ndeteriorate movement and coordination. One such condition is Parkinson\u2019s disease\n(PD), which primarily attacks the older masses and causes them discomfort in the\nlatter phases of their lives. Freezing of Gait (FOG), being a special symptom of\nPD, deteriorates mobility and degenerates quality of life. This study analyzed three\nphenomena known as FOG events, namely, Start Hesitation, Turn, and Walking. The\ngaps in existing research highlighting the scarcity of understanding of the mecha-\nnisms and factors leading to FOG events have been addressed and eliminated. This\nresearch aims to predict which of the three movements will most likely be affected.\nA four-step sequential approach is proposed that is initiated by the exploration of\npatients\u2019 accelerometer tests. The preprocessed, evenly sampled, and outlier-free\ndata is then subjected to feature engineering. Following metadata integration, the\nfeature-engineered dataset is fed to the Light Gradient Boosting Machine (LGBM)\ndue to its ability to handle extensive datasets. The suggested model computes the\nprobability of each of the three FOG events being impaired in a patient diagnosed\nwith Parkinson\u2019s disease. Precision was evaluated in the presence and absence of\noutliers for a comparative analysis. In the absence of outliers, LGBM gave a superior\nprecision of 0.7354, 0.8225, and 0.2689 for start hesitation, turning, and walking,\nrespectively.\nR. Doshi \u00b7 H. Gupta (B) \u00b7 P. Walavalkar \u00b7 D. Vartak \u00b7 N. Shekokar\nDwarkadas J, Sanghvi College of Engineering, Mumbai, India\ne-mail: ghardik5902@gmail.com\nR. Doshi\ne-mail: rishidoshi2002@gmail.com\nP. Walavalkar\ne-mail: praniketwalavalkar01@gmail.com\nD. Vartak\ne-mail: vartakdyuti@gmail.com\nN. Shekokar\ne-mail: narendra.shekokar@djsce.ac.in\n\u00a9 The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2025\nS. Kumar et al. (eds.), Proceedings of International Conference on Communication and\nComputational Technologies, Lecture Notes in Networks and Systems 1122,\nhttps://doi.org/10.1007/978-981-97-7426-5_16\n205\n206\nR. Doshi et al.\nKeywords Parkinson\u2019s disease \u00b7 Freezing of gait \u00b7 LGBM \u00b7 Accelerometer data \u00b7\nMovement impairments \u00b7 Machine learning\n1\nIntroduction\nParkinson\u2019s disease (PD) is a signi\ufb01cant neurological disorder that presents consider-\nable dif\ufb01culties for healthcare professionals. This chronic condition, which hampers\nmotor function, affects many individuals globally. Despite extensive research\nconducted on the biological aspects of Parkinson\u2019s disease, there are still numerous\naspects of this condition that remain elusive. Hence, further investigation is warranted\nto comprehend and develop remedies for the issue at hand comprehensively. A\ncharacteristic feature of Parkinson\u2019s disease (PD) is the gradual degeneration of\ndopaminergic neurons within the basal ganglia region of the brain. Motor symp-\ntoms, including bradykinesia, tremors, rigidity, and postural instability, can be\nattributed to a dopamine de\ufb01ciency. The causes of these symptoms can be attributed\nto an imbalance in neurotransmitter levels. Parkinson\u2019s disease has been associated\nwith autonomic dysfunction, affective abnormalities, sleep disturbances, cognitive\nimpairment, and motor dysfunction.\nFreezing of gait (FOG) is a puzzling and frustrating symptom of Parkinson\u2019s\ndisease (PD) and other Parkinsonian disorders. It creates frustration and immo-\nbility, making it dif\ufb01cult to start or sustain rhythmic, forward walking. FOG impairs\nmobility and independence, and falls, reducing quality of life. FOG can be caused\nor made worse by a variety of factors, both motor and non-motor. Problems with\ngait initiation, tight spaces, twisting motions, and interference from performing two\ntasks simultaneously are classic examples of FOG triggers. The majority of FOG\nevaluation strategies call for the use of FOG-provoking protocols. Patients diag-\nnosed with FOG are observed engaging in activities that may make their condition\nworse. Wearable technology has the potential to make FOG testing more effective.\nAdding more sensors can increase FOG detection, but this comes at the expense\nof compliance and overall usefulness. Therefore, combining these two approaches\ncan prove to be the most effective option. Accelerometers located in the lower back\ncombined with machine learning may accurately diagnose FOG, as incorporated\nand further discussed in this study. These algorithms are trained and evaluated using\nrelatively small datasets, severely restricting their generalizability. However, this\nresearch closes this gap by considering a large dataset of more than <no. of records>.\nThe primary objectives of this research are:\n\u2022 To evaluate the probability of each of the three movements incorporated in this\nstudy: Turn, Start hesitation, and Walking leading to FOG episodes. This contribu-\ntion would improve the diagnosis, comprehension, and treatment of FOG in order\nto better the lives of the many people who experience this debilitating Parkinson\u2019s\ndisease symptom.\nPredictive Analysis of Freezing of Gait Events in Parkinson\u2019s Disease \u2026\n207\n\u2022 Enhancing personalized therapy will lessen the burden of age-related movement,\ncognitive, and mobility impairments.\n\u2022 To demonstrate the attempts to gain a fresh understanding of the physiological and\npathophysiologic mechanisms underlying cognitive and motor function, the vari-\nables affecting these functions, and how they alter with age and illness, providing\nnew tools and methods for detecting and tracking cognitive and motor aging early\non.\nThe paper is organized by the introduction in Sect. 1, including the background on\nParkinson\u2019s disease, Freezing of Gait, and the scope and objective of this study.\nThe literature review in Sect. 2, which consists of the methods and gaps in the\nexisting research, is followed by the methodology in Sect. 3, which elucidates the\nproposed work\ufb02ow. The results of the proposed implementation are discussed in\nSect. 4, followed by the conclusion, which includes the summary and future scope\nof the study in Sects. 5 and 6, respectively.\n2\nLiterature Survey\nNumerous studies examined the use of deep learning and machine learning\napproaches to diagnose Parkinson\u2019s disease (PD) and identify episodes of freezing of\ngait (FoG), a prominent symptom in PD patients. Random forest classi\ufb01ers and KNN\nproved to be the most effective approaches for illness identi\ufb01cation. Some research\ncentered on identifying the illness using EEG and EMG signals. Techniques like\nsupport vector machines and AdaBoost achieved higher accuracy than other models.\nSrikanth [1] compares several Machine Learning classi\ufb01er algorithms imple-\nmented on a clinical images dataset, including XGBoost, Random Forest, KNN,\nand SVM, and proposes Random Forest as the best model since it offers superior\nperformance with an accuracy of 90%.\nThe major goal of Nissar et al. [2] is to evaluate the research on deep learning\nand machine learning methods used for the detection of Parkinson\u2019s disease. For\nclassi\ufb01cation purposes, a variety of models, including naive bayes, SVM, deep neural\nnetworks, decision trees, and random forests are successfully implemented. The\ndeep neural network attained the greatest accuracy of 99.49% among deep learning\ntechniques.\nIn order to identify PD at an early stage, Wang et al. [3] present a unique deep-\nlearning approach that takes into account a number of indicators, including Rapid Eye\nMovement and olfactory loss, cerebrospinal \ufb02uid data, and dopaminergic imaging\nmarkers. A comparison of the suggested deep learning model with twelve machine\nlearning and ensemble learning techniques using only a small amount of data demon-\nstrates the created model\u2019s better detection ability, which has the greatest accuracy\nof 96.45%.\nUsing their respective datasets, Raval et al. [4] implement machine learning algo-\nrithms such as Logistic Regression, SVM, Decision Tree, KNN, Stochastic Gradient\n208\nR. Doshi et al.\nDescent, and Gaussian Naive Bayes, as well as ensemble approaches like RF, Adap-\ntive Boosting, and Hard Voting. The most signi\ufb01cant result, with maximum accuracy\nof 99.79%, was obtained by RF on the Static Spiral Test (for detecting tremor).\nTadse et al. [5] employ and compare four machine learning algorithms: Decision\nTree, Logistic Regression, K-nearest neighbours, and Support vector machines for\nthe early prediction of PD. Decision Tree, yielding the highest accuracy of 94.87%,\nis suggested to be the model \ufb01t for predicting PD early and ef\ufb01ciently.\nIn their study, Kamoji et al. [6] employed various machine learning algorithms,\nincluding Logistic Regression, Naive Bayes, K-NN, RF, and Decision Tree Classi\ufb01er.\nThey applied the Decision Tree Classi\ufb01er on three different feature sets: the Freezing\nof Gait dataset, which was utilized to predict the presence of symptoms related to\nthe patient\u2019s legs and trunk by analyzing their gait; the Parkinson Clinical speech\ndataset, which aimed to detect deviations in audio frequency; and the Parkinson\nDisease wave analyzable dataset. It is suggested that employing a Decision Tree\nclassi\ufb01er on the FOG dataset, yielding an accuracy rate of 96.06%, represents the\noptimal and pragmatic approach.\nSVM, Logistic Regression, Discriminant Analysis, KNN, Decision tree, Random\nForest, Bagging tree, Naive Bayes, and AdaBoost are the nine Machine Learning\nAlgorithms (MLA) that are the subject of examination and assessment of Ouhmida\net al. [7]. The most effective algorithm is suggested to be KNN, which produces a\nmaximum accuracy of 97.22%.\nAnand et al. [8] incorporate Principal Component Analysis (PCA) and Kernel\nPrincipal Component Analysis as two dimensionality reduction (DR) techniques\nthat are used along with a variety of classi\ufb01cation-based machine learning and deep\nlearning algorithms. These algorithms are implemented and compared based on time\ncomplexity as a contributing factor. Using just 10 characteristics, it was found that\nKNN achieved the greatest accuracy, up to 95%.\nCelik et al. [9] conducted a comparative analysis of various classi\ufb01cation algo-\nrithms, including Logistic regression, SVM, Extra Trees, Gradient Boosting, and\nRF, to predict Parkinson\u2019s disease. The dataset\u2019s feature space was expanded due to\ncorrelation maps that were generated using Principal Component Analysis (PCA)\nand Information Gain (IG). The incorporation of expanded feature sets resulted in\nenhanced accuracy in the classi\ufb01cation of Parkinson\u2019s disease.\nSaikia et al. [10] are of the opinion that an electroencephalogram (EEG) and elec-\ntromyogram (EMG)-based GUI model would be a useful tool and genuine expla-\nnation for the early identi\ufb01cation of PD. Arti\ufb01cial neural networks extracted and\nclassi\ufb01ed EEG and EMG feature data.\nIn their research, Kumar et al. [11] propose a deep-learning model to identify\nParkinson\u2019s disease (PD). When applied to spiral photos, the model achieves high\ndetection and validation accuracies of 99.89% and 99.01%, respectively. Similarly,\nwhen applied to wave images, the model achieves detection and validation accuracies\nof 99.54% and 97.96%, respectively.\nDjuri-Jovii et al. [12] established an expert system for the automated categoriza-\ntion of various gait patterns. The method uses Pearson\u2019s correlation to distinguish\nbetween normal and pathological gaits and characterizes each step by its time, shank\nPredictive Analysis of Freezing of Gait Events in Parkinson\u2019s Disease \u2026\n209\ndisplacement, and spectral components. Strides that tremble or have a full motor\nblock are considered abnormal. In comparison to normal strides, abnormal strides\nwere found in 100% of the 12 patient datasets examined.\nMekruksavanich et al. [13] created the SE-DeepConvNet. It is a small, deep convo-\nlutional neural network with squeeze-and-excite parts that are specially designed\nfor fog identi\ufb01cation. To test how well the SE-DeepConvNet works, the authors\nuse the Daphnet dataset. The model\u2019s impressive 95.66% accuracy rate in their test\ndemonstrates that it is more effective than other deep learning models.\nAn automated approach for detecting freezing of gait is introduced by Abdallah\net al. [14], which utilizes convolutional neural networks (CNNs) to autonomously\nacquire and develop features and differentiate between instances of freezing occur-\nrences and regular gait. The suggested technique obviates the necessity of human\nfeature extraction and feature selection. With over 95% accuracy, speci\ufb01city, and\nsensitivity, the architecture described could tell the difference between freezing\nevents and normal walking.\nAccording to Khan et al. [15], wearable accelerometer sensors measured accel-\neration in three dimensions. They were used to do three different activities: walking\nalong a straight line, walking at random, and walking as usual. Following this, char-\nacteristics with signi\ufb01cant discriminatory power were fed into a classi\ufb01er to differen-\ntiate between regular accelerometer readings and instances of Freezing of Gait (FoG)\nidenti\ufb01ed using accelerometer data. Bagged Trees exhibited the highest degree of\naccuracy, attaining a classi\ufb01cation accuracy of 90.4%.\nFollowing the feature extraction process utilizing the Fast Fourier Transform\n(FFT) algorithm, Polat et al. [16] employed the logistic regression modelling for\nthe detection of freezing of gait (FoG) instances within the dataset. Remarkably, the\nachieved classi\ufb01cation accuracy for FoG cases related to Parkinson\u2019s Disease (PD)\nusing acceleration signals was 81.3%. Along with logistic regression, this study also\nlooked at how well four different classi\ufb01ers\u2014(SVM), Quadratic SVM, Cubic SVM,\nand k-Nearest Neighbors (kNN)\u2014could sort FoG cases.\nTahafchi et al. [17] introduce an innovative approach in their research paper to\ndetect halting of gait (FoG). This method categorizes occurrences of paralyzing\nepisodes by employing a support-vector-machine algorithm and temporal, spatial,\nand physiological variables. By utilizing a more extensive range of characteristics,\nthe methodology improves its ability to identify precise occurrences of Freezing of\nGait (FoG). Based on the \ufb01ndings, it can be inferred that the recently suggested\napproach demonstrates enhanced ef\ufb01cacy when the traditional energy-based method\nfails to produce desirable results (as indicated by an approximate area under the\nreceiver operator curve of 0.5). The receiver operator curve achieves an area of 0.96.\nZhang et al. [18] used strange walking patterns that happen before episodes of\nFreezing of Gait (FoG) to make a machine-learning model that could predict FoG\nepisodes. The purpose of making two prediction models with AdaBoost was to \ufb01nd\nout if adding compromised gait variables makes predicting Freezing of Gait (FoG)\nepisodes easier. According to the study\u2019s results, the proposed model showed a 5.7%\n210\nR. Doshi et al.\nimprovement in accuracy, giving it an overall accuracy rate of 82.7% during patient-\ndependent testing. Similarly, a signi\ufb01cant improvement of 9.8% in accuracy was\nobserved, leading to an accuracy rate of 77.9% during patient-independent testing.\nEven though many studies have looked at different parts of Parkinson\u2019s disease,\nwe still don\u2019t know much about how to predict and treat cognitive damage, espe-\ncially in the form of FOG, in people who have the disease. Much of the existing\nresearch has concentrated on motor symptoms and traditional therapies, leaving a\nconsiderable gap in our understanding of the mechanisms that contribute to FOG\nepisodes and effective measures for prediction and mitigation. The UCI dataset has\nlimitations in terms of complexity; however, the utilization of deep learning tech-\nniques has the potential to enhance accuracy by implementing ensemble approaches\nand expanding the dataset size. The FOG and speech datasets exhibited satisfactory\nperformance, although the wave and spiral data can be readily acquired. Traditional\nmachine learning methods have trouble capturing the complex relationships between\nsensor data and freezing of gait (FOG) in people with Parkinson\u2019s disease (PD).\nPrevious research has exhibited a de\ufb01ciency in conducting a thorough comparative\nexamination of existing approaches for detecting Freezing of Gait (FoG), largely\nemphasizing of\ufb02ine analysis of accelerometer data.\n3\nMethodology\nThe proposed work\ufb02ow commences with the inaugural step of data collection and\nexploration. Results of the 3D lower back accelerometer tests incorporating four\nattributes: subject, visit, test and medical condition were gathered and visualized.\nFollowing the successful collection of raw data, four preprocessing techniques\nwere utilized to enhance the data\u2019s quality and accuracy. Statistical methods were\nemployed to forecast and address missing values, categorical variables were trans-\nformed into actual numeric values, data was standardized using min\u2013max scaling,\nand possible outliers were identi\ufb01ed and removed through the utilization of box plots\nfor visualization purposes. Following that, the process of integrating metadata was\nconducted to enhance the data further, and the obtained feature-engineered data was\nprepared to be utilized for training the model. LGBM was selected as the regression\nmodel used to compute the probability of impairment of the three FOG events. The\noverview of the methodology has been mapped in Fig. 1.\n3.1\nDataset Description and Exploration\nThis study gathered data from reports of lower back 3D accelerometer tests of\npatients who were considered subjects. Two types of experiments were conducted to\nassess the data of the subjects. For instance, the TDCSFOG dataset was formulated\nfrom a data series collected in a lab where subjects completed a FOG-provoking\nPredictive Analysis of Freezing of Gait Events in Parkinson\u2019s Disease \u2026\n211\nFig. 1 System architecture\nprotocol. Each series of the TDCSFOG dataset was uniquely identi\ufb01ed based on\nfour attributes: subject, visit, test, and medical condition. The DeFOG dataset, on the\nother hand, consists of data series collected at home, where the subject completed\na FOG-provoking protocol. The series of this dataset incorporated three attributes:\nsubject, visit, and medical condition. Since the metadata for TDCSFOG is six times\nlarger than the DeFOG metadata, both are merged in order to analyze the informa-\ntion of all 107 patients. Another daily living dataset was incorporated, consisting\nof one week of continuous recordings of 65 subjects, of which 45 exhibited FOG\nsymptoms. The tdcsfog metadata identi\ufb01ed each series in the TDCSFOG dataset by\nunique Subject, Visit, Test and Medication conditions, whereas the DeFOG meta-\ndata identi\ufb01ed the DeFOG dataset records by unique Subject, Visit, and Medication\nconditions. The test set used for evaluation contained about 250 data series, of which\nTDCSFOG and DeFOG cases were in the same proportion as the training set.\nAfter careful and in-depth visualization of the combined dataset, certain trends\nwere deduced, as illustrated in Fig. 2. Approximately 80% of the participants are\nmen. More than 66% of the participants are 65\u201375 years old. Around 60% of the\nparticipants were diagnosed 5\u201315 years ago. Among participants aged between 80\nand 85, the majority are women.\nThe features correlation was also plotted to see how strongly or weakly they are\nrelated to each other as depicted in Fig. 3.\nFig. 2 Distribution of sex with respect to age and diagnosis\n212\nR. Doshi et al.\nFig. 3 Correlation between\nfeatures\n3.2\nData Preprocessing\nPreprocessing research data is crucial for producing reliable and informative results.\nThe method commences with addressing the matter of missing data, with speci\ufb01c\nfocus on the \u2018UPDRSIII_Off\u2019 \ufb01eld. This stage is crucial for avoiding information\ngapsandassuringthedata\u2019scompleteness.MultivariateImputationbyChainedEqua-\ntions (MICE) is crucial in this situation. The model considers complex relation-\nships between variables, enhancing the dataset\u2019s accuracy and representativeness\nfor further analysis. Additionally, it is critical to convert categorical attributes into\nstandardized numeric values in order to ensure that the dataset is properly organized\nand compatible with a wide range of analytical methods and algorithms. This stan-\ndardization facilitates the analysis process by ensuring consistency. Combining these\npreprocessing steps makes the dataset more dependable in preparation for statistical\nanalysis, machine learning, and modelling.\nHandling missing data: The process starts with a thorough dataset integrity assess-\nment. Each column is carefully checked for missing or \u201cnull\u201d numbers. Computing\nthe total count of null values in each column provides a complete picture of missing\ndata. This \ufb01rst evaluation makes it possible to discuss and \ufb01x these data gaps.\nThe UPDRSIIIOn/UPDRSIIIOff (Uni\ufb01ed Parkinson\u2019s Disease Rating Scale)\nrepresent scores when on and off medication, respectively. A lot of attention is paid to\nthe \u2018full_metadata\u2019 entry called \u2018UPDRSIII_Off.\u2019 This column is important because\nit shows important things about the \u2018UPDRSIII_Off\u2019 results. The goal is to \ufb01gure\nout how much data is missing from this area and how that \ufb01ts into the whole data set.\nThe null percentage in this column allows the algorithm to calculate the proportion\nof missing values relative to the dataset\u2019s size.\nA strong correlation between \u2018UPDRSIII_Off\u2019 scores and the \u2018UPDRSIII_On\u2019\nscores is identi\ufb01ed in Fig. 4. Also, there are some connections that aren\u2019t as strong\nbut can still be seen with attributes like age, gender, and the number of years since\nPredictive Analysis of Freezing of Gait Events in Parkinson\u2019s Disease \u2026\n213\nFig. 4 Relation between\nUPDRSII_OFF versus\nUPDRSIII_On\nthe diagnosis. This correlation shows how important it is to \ufb01ll in missing values,\nespecially in the above stated columns, where scores seem to be linked to other key\nvariables.\nImputation is seen as a good way to deal with the problem of \ufb01lling in the missing\nnumbers in these two columns. Imputation is \ufb01guring out what the missing values\nshould be based on the already known data and the relationships between the vari-\nables. Multivariate Imputation by Chained Equations (MICE) was the imputation\nmethod in this case. MICE is liked because it can deal with complex interdepen-\ndencies between variables. This makes it a good choice for cases in which variables\naffect each other. This model uses statistical methods to predict missing values in the\ncolumns given. Importantly, the imputation process is done slowly and uses the links\nand relationships between the different factors in the dataset to make more accurate\nestimates.\nOnce the missing values in the \u2018UPDRSIII_Off\u2019 and \u2018UPDRSIII_On\u2019 columns\nhave been guessed, the next step is to put these estimated values back into the dataset\ndisplayed in Fig. 5.\nConverting categorical features: This section fully explains how the categorical\nvariables in the research dataset were preprocessed. The focus is changing the cate-\ngorical variables in the \u2018defog_metadata_subjects\u2019 and \u2018tdcsfog_metadata_subjects\u2019\ndatasets. This step is very important because it turns categorical data into a standard\nformat that can be used for further research. It is important to understand the structure\nof these datasets.\nSpeci\ufb01cally, mapping changes are made to two factors. First, the \u2018sex\u2019 variable\nis changed, which stands for the biological and social construction of gender. The\nvalues \u2018F\u2019 for females and \u2018M\u2019 for males are 0 and 1, respectively. In the same way,\nmapping changes are made to the \u2018medication\u2019 variable, which shows the state of\nmedicine. The numerical numbers for \u201con\u201d and \u201coff\u201d are 0 and 1, respectively. This\nchange ensures that the representations of medication state are all the same, making\nit easier to do consistent and reliable analysis across the dataset. In order to ensure\n214\nR. Doshi et al.\nFig. 5 Relationship between\nage and difference of\nUPDRSIII_OFF\nand UPDRSIII_On\nthe future usability of the \u2018subject\u2019 and \u2018Id\u2019 variables, it is necessary to turn them\ninto real values at a later stage.\nNormalizing data: Normalization is a valuable preprocessing stage to ensure\nthat all variables are subjected to identical treatment in subsequent analyses. This\nprevents certain factors with larger values from dominating the analysis simply by\nvirtue of their magnitude. In order to execute this approach, a function is developed\nwith the explicit purpose of applying Min\u2013Max scaling to designated columns inside\na DataFrame.\nThe minimum and maximum values for the selected columns must be computed\nto implement the Min\u2013Max scale method. These values are required by the Min\u2013Max\nscaling method, which attempts to transform the data into a consistent range from\n0 to 1. This alteration guarantees the dimensions of all the data contained within\nthe chosen columns. The marginalized value can be obtained by subtracting the\nminimum value from the original data point. The result is subsequently divided by\nthe discrepancy between the greatest and lowest values. The result is then divided by\nthe minimum and utmost values. Individual execution of this procedure occurs for\nevery cell in the designated columns. The \ufb01nal output is a data frame, where each\ninteger has been normalized.\nUtilizing a normalized data frame as the outcome is crucial since it greatly\nenhances the accuracy and comparability of subsequent research. Normalizing data\nfacilitates the process of comparing and interpreting information by taking into\nconsideration the varying scales of the items. This guarantees that every variable\nhas an equitable in\ufb02uence on the analysis. This stage is crucial for data preparation\nfor data-driven tasks such as machine learning and statistical analysis.\nOutliers: The dataset includes a wide variety of event types, and the analysis\u2019s\naccuracy depends on the ability to distinguish between them. After the dataset is\ncompletely built and prepared for analysis, any occurrences of NaN (missing) values\nare removed. A box plot, as illustrated in Fig. 6, is utilized to represent the duration\nPredictive Analysis of Freezing of Gait Events in Parkinson\u2019s Disease \u2026\n215\nFig. 6 Box plot of features for checking outliers\nof occurrences across different event types visually. The graph illustrates the classi-\n\ufb01cation of events on the horizontal axis, while the vertical axis represents the time\nof each event. Box plots are an invaluable tool for \ufb01nding outliers since they visually\nre\ufb02ect data\u2019s spread and central tendency. Annotations improve the box plot, espe-\ncially by drawing attention to the highest values, which show where the whiskers\nend for each event category.\nAn integral aspect of the research process is the identi\ufb01cation of outliers, which\nrefer to data points that deviate signi\ufb01cantly from the expected range. A temporal\nthreshold of 200 s is established in order to identify and isolate outliers. Possible\noutliers are data points that exceed this level. It is crucial to acknowledge that the\nselection of this level holds signi\ufb01cant importance, as it is typically selected care-\nfully to enhance the model\u2019s performance during subsequent \ufb01ne-tuning stages. The\nsubsequent stage of the procedure involves eliminating any data points that deviate\nsigni\ufb01cantly from the rest of the dataset. The box plot provides a distinct frame\nof reference for this task since it visually represents the maximum value for each\noccurrence category. Rows in the \u2018events_df\u2019 data frame that exceed the maximum\nthreshold by a margin greater than 200 s are eliminated, hence eliminating any\npotential outliers. The dataset \u201cevents_\ufb01ltered\u201d contains the processed data, which\nhave been effectively cleansed of potential outliers. Additionally, adding this revised\ndataset is important for ensuring that future analyses or modelling work is accurate\nand reliable because it shows event durations more clearly and accurately.\n216\nR. Doshi et al.\n3.3\nFeature Engineering\nFeature engineering involves loading data, integrating metadata, normalizing\naccelerometer readings, and creating a range of features to augment the dataset.\nA reader function is designed to process \ufb01les containing sensor data and execute\na sequence of operations to preprocess the data for analysis. The function has the\ncapability to accept arguments, such as \u2018\ufb01le\u2019, \u2018module\u2019, and \u2018pre_type\u2019, which can\nbe utilized to modify its behaviour based on the speci\ufb01c circumstances. The func-\ntion uses the \u2018pd.read_csv\u2019 method to retrieve data from the designated \ufb01le. The\nidentity, sometimes referred to as \u201cId,\u201d is extracted from the \ufb01le path and subse-\nquently assigned to a new column in the dataframe. The \u2018module\u2019 argument is used\nto select \u2018defog_metadata_subjects\u2019 or \u2018tdcsfog_metadata_subjects\u2019 as methods for\nincorporating metadata into the data. Various feature engineering techniques are\napplied to the accelerometer data. The columns of accelerometer data called \u201cAccV,\u201d\n\u201cAccML,\u201d and \u201cAccAP\u201d are changed in different ways so that their properties can be\nstudied. Accelerometer data for corresponding FOG events like \u201cAccV,\u201d \u201cAccML,\u201d\nand \u201cAccAP\u201d is shown in Fig. 7.\nThese changes include normalization, cumulative summation, and calculating\nmoving statistics like sum, minimum, maximum, mean, standard deviation, and delta.\nAlso, exponentially weighted moving averages (EWMA) are calculated to show how\nthe data behaves differently. We can \ufb01gure out other things about the object from\nfacts about time. If events are found, the function will give a return value of \u201cNone,\u201d\nwhich means that the information linked with this \u201cId\u201d is not good for training. The\nprocessed data is put into two different data frames. Adopting this full approach\nensures that the data is well-prepared, standardized, and has many different features,\nmaking it more suitable for the research question.\nFig. 7 Effect of accelerometer data on various episodes\nPredictive Analysis of Freezing of Gait Events in Parkinson\u2019s Disease \u2026\n217\n3.4\nModel Selection and Training\nWithin this particular section, we aim to provide a comprehensive explanation for the\ndecision to employ the Light Gradient Boosting Machine (LGBM) as the primary\npredictive model for our research endeavour. In this discussion, we will explore the\nprominent characteristics that make LGBM a noteworthy selection and examine its\noperational mechanism, providing a clear understanding of how it aligns with the\ngoals of this research.\nThe selection of LGBM as the major predictive model for our research is based on\nseveral convincing factors, including its ef\ufb01ciency and scalability, utilization of regu-\nlarization techniques, capacity to handle categorical data, and strong performance\non big datasets [19]. Due to its remarkable computational ef\ufb01ciency, the LGBM\napproach is an excellent option for managing massive datasets and feature spaces\nwith high-dimensionalities. The memory-optimized architecture and ability to effec-\ntively handle substantial volumes of data align nicely with our research goals. Due\nto the presence of continuous 3D accelerometer readings in the dataset, there is a\nsubstantial volume of data. To effectively manage this, it is necessary to build a\nmemory-optimized architecture.\nIncluding many regularization techniques and early stopping mechanisms in\nLGBM [20] supports our choice of this model as the main prediction model for\nour study. L1 (Lasso) and L2 (Ridge) regularization are two of the regularization\nmethods that the model provides. Over\ufb01tting can be reduced using these techniques\nby adding penalty terms to the loss function (1). Additionally, the strategy includes\nthe early stopping method. This crucial component assesses the model\u2019s performance\non a separate validation dataset throughout the training phase and immediately halts\nthe training if over\ufb01tting is detected. These complementary techniques ensure the\nresilience and optimal generalization performance of the model. They are a fantastic\n\ufb01t for the goals of our investigation.\nL(\u03b8) =\n\u0002N\ni=1L(yi, F(xi, \u03b8)) + \u03bb\u0004(\u03b8)\n(1)\nwhere, L(\u03b8) represents loss function, \u03bb is the regularization parameter, and \u0004(\u03b8) is\nthe regularization term.\nBecause of its high pace and scalability, LGBM is a perfect \ufb01t for our research\n[20]. This is perfect for circumstances where obtaining high anticipated accuracy\nand ef\ufb01ciency are equally crucial. Without the need for preprocessing, the model can\nhandle both numerical and categorical features with ef\ufb01ciency. The LGBM algo-\nrithm contains a number of adjustable parameters that let you manage the model\u2019s\ncomplexity and lower the risk of over\ufb01tting. Given the dataset\u2019s label targets, a\nsupervised learning approach was employed to address the problem. This task can\nbe categorized as a multi-class classi\ufb01cation problem due to the inclusion of various\nobjectives, such as turning, walking, and starting. The vast dataset must be classi\ufb01ed\nutilizing a robust and ef\ufb01cient methodology. Employing a model like LightGBM\n218\nR. Doshi et al.\n(LGBM) is necessary to tackle the problem of imbalanced datasets in multi-class\nsituations.\nA gradient boosting algorithm called the Light Gradient Boosting Machine\n(LGBM) repeatedly generates a set of decision trees. The model can progressively\nlearn and modify its predictions when this ensemble methodology is used. Every\nadditional tree in the ensemble is created to \ufb01x any mistakes or incorrect classi-\n\ufb01cations made by the trees that came before it. This algorithm\u2019s usage of a leaf-\nwise tree expansion technique is one of its key features. In contrast to the conven-\ntional approach, which \ufb01rst expands a tree from depth, LGBM employs a strategy\nthat involves choosing the leaf node that provides the greatest loss reduction for\nexpansion [21]. This process often produces more fair and deep trees, enabling the\nmodel to depict complex relationships in our data accurately. Moreover, it optimizes\nthe procedure by gradually converging towards the best solution using the gradient\ndescent technique. A regulated method to obtain the optimal model is made possible\nby the learning rate parameter, which controls the size of each step taken during\noptimization.\nIn order to determine the optimal parameters for the LightGBM method, a Grid-\nSearchCV procedure is conducted using the speci\ufb01ed parameter grid. The parameter\ngrid consists of three hyperparameters: max_depth, learning_rate, and n_estimators.\nFor the max_depth hyperparameter, the values 6, 8, and 10 are considered. The\nlearning_rate hyperparameter is evaluated using the values 0.15, 0.1, and 0.01.\nLastly, the n_estimators hyperparameter is explored with the values 50, 70, and\n90. The optimal parameter values used for this study are as follows: max_depth = 8,\nlearning_rate = 0.1, and n_estimators = 70. Furthermore, as part of the \ufb01ne-tuning\nprocedure, the variables UPDRSIII_On and UPDRSIII_Off were excluded from the\ntdcsfog dataframe.\nThe key components that make LGBM exceptionally appropriate have been\nidenti\ufb01ed and highlighted. Furthermore, an extensive understanding of its working\nmechanism and pertinent mathematical notations and formulas have been clari\ufb01ed.\nThe convergence of these characteristics provides us with a robust modelling and\nforecasting tool and successfully synchronizes the LGBM model with our study\ngoals.\n4\nResults and Discussion\nThe accelerometer data used to train the LGBM (Light Gradient Boosting Machine)\nregression model was the most important part of this study. The model\u2019s performance\nwas comprehensively evaluated using various metrics on a testbed consisting of 4682\ninstances and 46 features. The evaluation metrics were employed to evaluate the\neffectiveness and accuracy of the proposed methodology. The model outputs three\nprobabilities, each pertaining to an FOG event, an instance listed in Table 1.\nK-fold cross-validation, a resampling method involving the division of the dataset\ninto k subsets, was utilized in this study to assess the performance of the LGBM\nPredictive Analysis of Freezing of Gait Events in Parkinson\u2019s Disease \u2026\n219\nTable 1 A small sample of\nthe output of test cases\nInstance ID\nStart hesitation\nTurn\nWalking\n003f117e14_867\n0.0169633\n0.0186592\n0.0001075\n003f117e14_874\n0.0169633\n0.0183729\n0.0001246\n003f117e14_876\n0.0149632\n0.0183729\n0.0001192\n003f117e14_1828\n0.0012843\n0.2931558\n0.0003868\n003f117e14_1953\n0.0012843\n0.2877404\n0.0004175\n003f117e14_2163\n0.0015811\n0.227426\n0.000382\n003f117e14_2244\n0.0010171\n0.1939136\n0.0003706\n003f117e14_2375\n0.0013712\n0.206998\n0.0004054\n003f117e14_2616\n0.0009333\n0.204171\n0.0004077\nregressionmodel.Inordertoguaranteetheattainmentofunbiasedresults,avalidation\nsetwasconstructedfromeachfold,withtheremainingfoldsbeingutilizedfortraining\nintentions. Group-based cross-validation with the \u201cId\u201d column for partitioning was\nchosen to deal with data dependencies and reduce the chance of over\ufb01tting. The\nmethod mentioned above included an analysis of the built-in group structures. This\nmade the model better at predicting different situations and allowed for a more\naccurate evaluation of its performance.\nTheevaluationcriterionutilizedinthisstudyisthemeanaverageprecision(MAP),\nwhich is a metric that quanti\ufb01es the average precision of predictions made for each\nevent class. Hence, placing greater importance on accurately predicting event cate-\ngories is more signi\ufb01cant than attaining complete precision in forecasting all events.\nAccording to Table 2, the inclusion of outliers impacts the precision of the results,\nbut not signi\ufb01cantly, given that healthcare scenarios often involve atypical cases.\nThe primary causes of a FOG (Fog of War) incident are hesitation and turning.\nThere are big differences between what was observed and what was evaluated on the\ntest, which suggests that the evaluation might not have been accurate if the above\ndata were used.\nTable 2 Precision of FOG event contribution in the presence and absence of outliers\nFOG event\nPrecision with outliers\nPrecision without outliers\nStart hesitation\n0.7138\n0.7354\nTurning\n0.8231\n0.8225\nWalking\n0.253\n0.2689\nOverall\n0.5967\n0.6111\n220\nR. Doshi et al.\n5\nConclusion\nFreezing of gait (FOG) refers to the abrupt impairment in the capacity to execute\nturning movements, commence walking, or maintain locomotion in individuals who\nhave Parkinson\u2019s disease. The above phenomenon exerts detrimental effects on indi-\nviduals\u2019 mental and physical well-being, making them susceptible to increased likeli-\nhood of falls and diminished autonomy. Among the several approaches for assessing\nFOG, the most effective technique entails employing wearable devices to conduct\nFOG-inducing tests. This study employs machine learning models to compute the\nprobability of each of the three FOG movements described above being hampered\nin a patient diagnosed with Parkinson\u2019s. These probabilities are derived from data\ncollected via a lower back accelerometer worn by individuals with Parkinson\u2019s\ndisease. The LightGBM algorithm is employed as a regressor to evaluate proba-\nbility. Upon testing the algorithm in the presence and absence of outliers, it was\ndeduced that LGBM performed better, yielding a precision of 61.11% overall. The\nlow precision for walking suggests that it is a rare FOG event with a low probability\nof occurrence. Therefore, the need for prediction of impairment in FOG patients has\nbeen addressed in this study to enhance medical attention to such patients, especially\nseniors who desperately need mitigation in such disturbing conditions.\nReferences\n1. Srikanth R (2022) Parkinson disease detection using various machine learning algorithms.\nIn: 2022 international conference on advanced computing technologies and applications\n(ICACTA). IEEE\n2. Nissar I, Mir WA, Shaikh TA (2021) Machine learning approaches for detection and diagnosis\nof Parkinson\u2019s disease-a review. In: 2021 7th international conference on advanced computing\nand communication systems (ICACCS), vol 1. IEEE\n3. Wang W et al (2020) Early detection of Parkinson\u2019s disease using deep learning and machine\nlearning. IEEE Access 8:147635\u2013147646\n4. Raval S, Balar R, Patel V (2020) A comparative study of early detection of Parkinson\u2019s\ndisease using machine learning techniques. In: 2020 4th international conference on trends\nin electronics and informatics (ICOEI)(48184). IEEE\n5. Tadse S, Jain M, Chandankhede P (2021) Parkinson\u2019s detection using machine learning. In:\n2021 5th international conference on intelligent computing and control systems (ICICCS).\nIEEE\n6. Kamoji S et al (2021) Prediction of Parkinson\u2019s disease using machine learning and deep\ntransfer learning from different feature sets. In: 2021 6th international conference on\ncommunication and electronics systems (ICCES). IEEE\n7. Ouhmida A et al (2022) Parkinson\u2019s disease classi\ufb01cation using machine learning algorithms:\nperformance analysis and comparison. In: 2022 2nd international conference on innovative\nresearch in applied science, engineering and technology (IRASET). IEEE\n8. Anand A et al (2018) Evaluation of machine learning and deep learning algorithms combined\nwith dimensionality reduction techniques for classi\ufb01cation of Parkinson\u2019s disease. In: 2018\nIEEE international symposium on signal processing and information technology (ISSPIT).\nIEEE\nPredictive Analysis of Freezing of Gait Events in Parkinson\u2019s Disease \u2026\n221\n9. Celik E, Omurca SI (2019) Improving Parkinson\u2019s disease diagnosis with machine learning\nmethods. In: 2019 scienti\ufb01c meeting on electrical-electronics & biomedical engineering and\ncomputer science (EBBT). Ieee\n10. Saikia A et al (2020) Machine learning based diagnostic system for early detection of\nParkinson\u2019s disease. In: 2020 international conference on computational performance eval-\nuation (ComPE). IEEE\n11. Kumar T, Tiwari A, Yadav V (2022) Early detection of parkinson\u2019s disease using convolu-\ntional neural network. In: 2022 \ufb01fth international conference on computational intelligence\nand communication technologies (CCICT). IEEE\n12. Djuri\u0107-Jovi\u010di\u0107 MD, Jovi\u010di\u0107 NS, Radovanovi\u0107 SM, Stankovi\u0107 ID, Popovi\u0107 MB, Kosti\u0107 VS\n(2013) Automatic identi\ufb01cation and classi\ufb01cation of freezing of gait episodes in parkinson\u2019s\ndisease patients. IEEE Trans Neural Syst Rehabil Eng 22(3):685\u2013694\n13. Mekruksavanich S, Jitpattanakul A (2021) Detection of freezing of gait in parkinson\u2019s disease\nby squeeze-and-excitation convolutional neural network with wearable sensors. In: 2021 15th\ninternational conference on open source systems and technologies (ICOSST). IEEE, pp 1\u20135\n14. Abdallah M, Saad A, Ayache M (2019) Freezing of gait detection: deep learning approach. In:\n2019 international arab conference on information technology (ACIT). IEEE, pp 259\u2013261\n15. Khan AZ, Aamir F, Kafeel A, Khan MU, Aziz S (2021) Freezing of gait detection in parkinson\u2019s\ndisease from accelerometer readings. In: 2021 Mohammad Ali Jinnah University international\nconference on computing (MAJICC). IEEE, pp 1\u20135\n16. Polat K (2019) Freezing of gait (fog) detection using logistic regression in parkinson\u2019s disease\nfrom acceleration signals. In: 2019 scienti\ufb01c meeting on electrical-electronics & biomedical\nengineering and computer science (EBBT). Ieee, pp 1\u20134\n17. Tahafchi P, Molina R, Roper JA, Sowalsky K, Hass CJ, Gunduz A, Judy JW (2017) Freezing-of-\ngait detection using temporal, spatial, and physiological features with a support-vector-machine\nclassi\ufb01er. In: 2017 39th annual international conference of the IEEE engineering in medicine\nand biology society (EMBC). IEEE, pp 2867\u20132870\n18. Zhang Y, Yan W, Yao Y, Bint Ahmed J, Tan Y, Gu D (2020) Prediction of freezing of gait\nin patients with Parkinson\u2019s disease by identifying impaired gait patterns. IEEE Trans Neural\nSyst Rehabil Eng 28(3):591\u2013600\n19. \u0141o\u015b H, Mendes GS, Cordeiro D, Grosso N, Costa H, Benevides P, Caetano M (2021) Evaluation\nof XGBoost and LGBM performance in tree species classi\ufb01cation with sentinel-2 data. In: 2021\nIEEE international geoscience and remote sensing symposium IGARSS. IEEE, pp 5803\u20135806\n20. Lin M, Ma L (2021) Research on setting voltage of electrolyzer based on LGBM-LSTM algo-\nrithm. In: 2021 IEEE 4th international conference on computer and communication engineering\ntechnology (CCET). IEEE, pp 414\u2013419\n21. Shukla A, Chettiar G, Choudhary A, Thakur A, Kumar S (2022) Integrating comparison of\nmalware detection classi\ufb01cation using LGBM and XGB machine learning algorithms. In: 2022\nIEEE international conference on blockchain and distributed systems security (ICBDS). IEEE,\npp 1\u20137\n", "filename": "Parkinsons.pdf", "created_at": "2025-05-21T17:26:22.327157"}
{"doc_id": "fdacdb43-0bf4-4c2a-b6d6-82ff0dd5c028", "source_type": "email", "title": "Re: Order Issue - ORD0023", "sender": "support@company.com", "body": "Dear Customer,\n\nThank you for reaching out about your recent order (ORD0023). We're sorry to hear that the product arrived damaged. We take quality issues very seriously.\n\nOur support team has initiated a replacement, and you should receive it within 5-7 business days. In the meantime, please dispose of the damaged product or return it using the prepaid label attached.\n\nIf you have any further concerns, feel free to reply to this email.\n\nSincerely,\nSupport Team\nCompany Inc.\n", "filename": "sample_email.eml", "created_at": "2025-05-21T17:20:31.531013"}
